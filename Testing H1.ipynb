{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rduZrTPNaRUQ"
      },
      "outputs": [],
      "source": [
        "pip install mlxtend\n",
        "pip install scikit-optimize\n",
        "pip install deap\n",
        "pip install pyswarms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcCXqtayzfTm"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plot\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import mlxtend\n",
        "from mlxtend.evaluate import bias_variance_decomp\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nk4sVJvGv0e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "dfa = pd.read_csv(r'...')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLfzKzeJ9z3O"
      },
      "outputs": [],
      "source": [
        "df1 = dfa.drop(columns = ['SubjectID', 'VideoID','predefinedlabel'])\n",
        "df1.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iLU1WxUecwl"
      },
      "outputs": [],
      "source": [
        "df = df1.sample(frac =0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHKSStAH1TnH"
      },
      "outputs": [],
      "source": [
        "df['user-definedlabeln'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBCYR48zTeQj"
      },
      "source": [
        "feature preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVmMCV9jTouA"
      },
      "outputs": [],
      "source": [
        "# Splitting into train, val and test set -- 80-10-10 split\n",
        "\n",
        "# First, an 70-30 split\n",
        "train_df, test_df = train_test_split(df, test_size = 0.3, random_state = 113)\n",
        "\n",
        "# Then split the 20% into half\n",
        "val_df, test_df = train_test_split(test_df, test_size = 0.5, random_state = 113)\n",
        "\n",
        "ic = df.columns.tolist()\n",
        "ic.remove('user-definedlabeln')\n",
        "\n",
        "oc = ['user-definedlabeln']\n",
        "\n",
        "ytrain = train_df[oc]\n",
        "X_train = train_df.drop(columns = oc)\n",
        "\n",
        "yval = val_df[oc]\n",
        "X_val = val_df.drop(columns = oc)\n",
        "\n",
        "ytest = test_df[oc]\n",
        "X_test = test_df.drop(columns = oc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSS9Opd_euZ1"
      },
      "source": [
        "**Training SVM in Default Parameters (Control Model)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFQOo6i9etKj"
      },
      "outputs": [],
      "source": [
        "from sklearn import  svm\n",
        "svm = svm.SVC()\n",
        "\n",
        "svm.fit(X_train,ytrain)\n",
        "print(f'The accuracy score of the model is {svm.score(X_test,ytest.values.ravel()):.5f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgL1ABTffrlF"
      },
      "outputs": [],
      "source": [
        "params = svm.get_params()\n",
        "params_df = pd.DataFrame(params, index=[0])\n",
        "params_df.T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNT2SFs_p9PO"
      },
      "source": [
        "**Training SVM using Hyper Parameter Tuning (Experimental Model)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mR95kZo2uC5i"
      },
      "outputs": [],
      "source": [
        "from sklearn import  svm\n",
        "svm1 = svm.SVC(kernel='rbf', C=7, degree = 1, gamma= 'scale', probability = True)\n",
        "svm1.fit(X_train,ytrain)\n",
        "print(f'The accuracy score of the model is {svm.score(X_test,ytest.values.ravel()):.5f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsfTEH7DYUFO"
      },
      "source": [
        "**Decomposing Bias and Variance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYE2RH3nbTH4"
      },
      "source": [
        "*passing pandas dataframe to numpy array as the mlxtend package does not support dataframe*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7X4-LcScbbGv"
      },
      "outputs": [],
      "source": [
        "X_train=X_train.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D09_kZ0ecAVv"
      },
      "outputs": [],
      "source": [
        "X_test=X_test.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vajU8-lVcGdZ"
      },
      "outputs": [],
      "source": [
        "ytrain=ytrain.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AW_SWCfacLwZ"
      },
      "outputs": [],
      "source": [
        "ytest=ytest.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "335PkSYbbb-m"
      },
      "source": [
        "**Decomposing Bias Variance in Control Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMz3eqHsYTY9"
      },
      "outputs": [],
      "source": [
        "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
        "        svm, X_train, ytrain, X_test, ytest,\n",
        "        loss='0-1_loss',\n",
        "        random_seed=123)\n",
        "\n",
        "print('Average expected loss: %.3f' % avg_expected_loss)\n",
        "print('Average bias: %.3f' % avg_bias)\n",
        "print('Average variance: %.3f' % avg_var)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Acf4MUa6yXDk"
      },
      "source": [
        "**Decomposing Bias Variance in Experimental Model**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bJkC-Azkw2l3"
      },
      "outputs": [],
      "source": [
        "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
        "        svm1, X_train, ytrain, X_test, ytest,\n",
        "        loss='0-1_loss',\n",
        "        random_seed=123)\n",
        "\n",
        "print('Average expected loss: %.3f' % avg_expected_loss)\n",
        "print('Average bias: %.3f' % avg_bias)\n",
        "print('Average variance: %.3f' % avg_var)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyper Paramter Tuning Algorithms**"
      ],
      "metadata": {
        "id": "FAVdEAs7dv3J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Random Search"
      ],
      "metadata": {
        "id": "uV08C8rAfI7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, cross_val_score\n",
        "from hyperopt import tpe, STATUS_OK, Trials, hp, fmin, STATUS_OK, space_eval\n",
        "\n",
        "# List of C values\n",
        "C_range = np.logspace(-1, 1, 3)\n",
        "print(f'The list of values for C are {C_range}')\n",
        "# List of gamma values\n",
        "gamma_range = np.logspace(-1, 1, 3)\n",
        "print(f'The list of values for gamma are {gamma_range}')\n",
        "The list of values for C are [ 0.1  1.  10. ]\n",
        "The list of values for gamma are [ 0.1  1.  10. ]\n",
        "\n",
        "# Define the search space\n",
        "param_grid = {\n",
        "    # Regularization parameter.\n",
        "    \"C\": C_range,\n",
        "    # Kernel type\n",
        "    \"kernel\": ['rbf', 'poly'],\n",
        "    # Gamma is the Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’.\n",
        "    \"gamma\": gamma_range.tolist()+['scale', 'auto']\n",
        "    }\n",
        "# Set up score\n",
        "scoring = ['accuracy']\n",
        "# Set up the k-fold cross-validation\n",
        "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)\n",
        "# Define random search\n",
        "random_search = RandomizedSearchCV(estimator=svm,\n",
        "                           param_distributions=param_grid,\n",
        "                           n_iter=500,\n",
        "                           scoring=scoring,\n",
        "                           refit='accuracy',\n",
        "                           n_jobs=-1,\n",
        "                           cv=kfold,\n",
        "                           verbose=0)\n",
        "# Fit grid search\n",
        "random_result = random_search.fit(X_train, ytrain)\n",
        "# Print grid search summary\n",
        "random_result"
      ],
      "metadata": {
        "id": "x0yTny5NlQQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Bayesian Optimization"
      ],
      "metadata": {
        "id": "6EeZ8vVafthh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import gp_minimize\n",
        "\n",
        "# Define the function to optimize (fitness function)\n",
        "def svm_accuracy(params):\n",
        "    C = params[0]  # Regularization parameter\n",
        "    gamma = params[1]  # Kernel coefficient for 'rbf', 'poly', and 'sigmoid'\n",
        "    degree = int(params[2])  # Degree of the polynomial kernel (for 'poly' only)\n",
        "\n",
        "    svm_model = svm(C=C, kernel='rbf' if degree == 2 else 'poly' if degree > 2 else 'linear',\n",
        "                    gamma=gamma, degree=degree, random_state=42)\n",
        "    svm_model.fit(X_train, ytrain)\n",
        "    y_pred = svm_model.predict(X_test)\n",
        "    accuracy = accuracy_score(ytest, y_pred)\n",
        "\n",
        "    return 1.0 - accuracy  # Minimize 1 - accuracy to maximize accuracy\n",
        "\n",
        "# Set up the hyperparameter search space for Bayesian optimization\n",
        "space = [(0.1, 100.0),  # C: regularization parameter\n",
        "         (0.01, 10.0),   # gamma: kernel coefficient for 'rbf', 'poly', and 'sigmoid'\n",
        "         (2, 5)]         # degree: degree of the polynomial kernel (for 'poly' only)\n",
        "\n",
        "# Perform Bayesian optimization\n",
        "result = gp_minimize(func=svm_accuracy, dimensions=space, n_calls=50, random_state=42)\n",
        "\n",
        "# Extract the best hyperparameters from the optimization results\n",
        "best_C, best_gamma, best_degree = result.x\n",
        "best_degree = int(best_degree)  # Ensure the degree is an integer\n",
        "\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(\"C =\", best_C)\n",
        "print(\"Gamma =\", best_gamma)\n",
        "print(\"Degree =\", best_degree)\n",
        "\n",
        "# Train the SVM model with the best hyperparameters and evaluate on the test set\n",
        "best_svm_model = svm(C=best_C, kernel='rbf' if best_degree == 2 else 'poly' if best_degree > 2 else 'linear',\n",
        "                     gamma=best_gamma, degree=best_degree, random_state=42)\n",
        "best_svm_model.fit(X_train, ytrain)\n",
        "y_pred = best_svm_model.predict(X_test)\n",
        "test_accuracy = accuracy_score(ytest, y_pred)\n",
        "print(\"Test Accuracy with Best Model:\", test_accuracy)"
      ],
      "metadata": {
        "id": "muXkg5Hll_kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Genetic Algorithm"
      ],
      "metadata": {
        "id": "YzGRB40XCuwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from deap import base, creator, tools, algorithms\n",
        "\n",
        "\n",
        "# Create a function to evaluate the fitness of an individual (set of hyperparameters)\n",
        "def evaluate_svm(individual):\n",
        "    C = individual[0]  # Regularization parameter\n",
        "    kernel = individual[1]  # Kernel type ('linear', 'poly', 'rbf', 'sigmoid')\n",
        "    degree = individual[2]  # Degree of the polynomial kernel (for 'poly' only)\n",
        "\n",
        "    svm_model = svm(C=C, kernel=kernel, degree=degree, random_state=42)\n",
        "    svm_model.fit(X_train, ytrain)\n",
        "    y_pred = svm_model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    return accuracy,\n",
        "\n",
        "# Genetic algorithm setup\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "# Define the hyperparameter search space\n",
        "# Here, we are tuning the 'C' (regularization parameter),\n",
        "# 'kernel' (type of kernel), and 'degree' (for polynomial kernel) hyperparameters.\n",
        "toolbox.register(\"attr_C\", random.uniform, 0.1, 100)\n",
        "toolbox.register(\"attr_kernel\", random.choice, ['linear', 'poly', 'rbf', 'sigmoid'])\n",
        "toolbox.register(\"attr_degree\", random.randint, 2, 5)\n",
        "toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
        "                 (toolbox.attr_C, toolbox.attr_kernel, toolbox.attr_degree), n=1)\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "toolbox.register(\"evaluate\", evaluate_svm)\n",
        "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
        "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.1)\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "\n",
        "def main():\n",
        "    pop_size = 10\n",
        "    num_generations = 5\n",
        "    cx_prob = 0.5\n",
        "    mut_prob = 0.2\n",
        "\n",
        "    population = toolbox.population(n=pop_size)\n",
        "\n",
        "    print(\"Starting Genetic Algorithm...\")\n",
        "    for gen in range(num_generations):\n",
        "        offspring = algorithms.varAnd(population, toolbox, cxpb=cx_prob, mutpb=mut_prob)\n",
        "        fits = toolbox.map(toolbox.evaluate, offspring)\n",
        "        for fit, ind in zip(fits, offspring):\n",
        "            ind.fitness.values = fit\n",
        "\n",
        "        population = toolbox.select(offspring, k=len(population))\n",
        "\n",
        "    best_individual = tools.selBest(population, k=1)[0]\n",
        "    best_C, best_kernel, best_degree = best_individual\n",
        "    print(\"Best Hyperparameters:\")\n",
        "    print(\"C =\", best_C)\n",
        "    print(\"Kernel =\", best_kernel)\n",
        "    print(\"Degree =\", best_degree)\n",
        "\n",
        "    best_model = SVC(C=best_C, kernel=best_kernel, degree=best_degree, random_state=42)\n",
        "    best_model.fit(X_train, y_train)\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    test_accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(\"Test Accuracy with Best Model:\", test_accuracy)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "fjNEuoiqfxmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Particle Swarm Optimization"
      ],
      "metadata": {
        "id": "Xeye-IAPE1Uw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyswarms as ps\n",
        "\n",
        "# Define the function to optimize (fitness function)\n",
        "def svm_accuracy(params):\n",
        "    C = params[0]  # Regularization parameter\n",
        "    gamma = params[1]  # Kernel coefficient for 'rbf', 'poly', and 'sigmoid'\n",
        "    degree = int(params[2])  # Degree of the polynomial kernel (for 'poly' only)\n",
        "\n",
        "    svm_model = svm(C=C, kernel='rbf' if degree == 2 else 'poly' if degree > 2 else 'linear',\n",
        "                    gamma=gamma, degree=degree, random_state=42)\n",
        "    svm_model.fit(X_train, ytrain)\n",
        "    y_pred = svm_model.predict(X_test)\n",
        "    accuracy = accuracy_score(ytest, y_pred)\n",
        "\n",
        "    return 1.0 - accuracy  # Minimize 1 - accuracy to maximize accuracy\n",
        "\n",
        "# Set up the hyperparameter search space for PSO optimization\n",
        "lower_bound = [0.1, 0.01, 2]  # Lower bounds for C, gamma, degree\n",
        "upper_bound = [100.0, 10.0, 5]  # Upper bounds for C, gamma, degree\n",
        "bounds = (lower_bound, upper_bound)\n",
        "\n",
        "# Set up the PSO optimizer\n",
        "options = {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
        "optimizer = ps.single.GlobalBestPSO(n_particles=10, dimensions=3, options=options, bounds=bounds)\n",
        "\n",
        "# Perform PSO optimization\n",
        "best_cost, best_params = optimizer.optimize(svm_accuracy, iters=50)\n",
        "\n",
        "# Extract the best hyperparameters from the optimization results\n",
        "best_C, best_gamma, best_degree = best_params\n",
        "best_degree = int(best_degree)  # Ensure the degree is an integer\n",
        "\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(\"C =\", best_C)\n",
        "print(\"Gamma =\", best_gamma)\n",
        "print(\"Degree =\", best_degree)\n",
        "\n",
        "# Train the SVM model with the best hyperparameters and evaluate on the test set\n",
        "best_svm_model = svm(C=best_C, kernel='rbf' if best_degree == 2 else 'poly' if best_degree > 2 else 'linear',\n",
        "                     gamma=best_gamma, degree=best_degree, random_state=42)\n",
        "best_svm_model.fit(X_train, y_train)\n",
        "y_pred = best_svm_model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test Accuracy with Best Model:\", test_accuracy)"
      ],
      "metadata": {
        "id": "dabAlpU3Ez7q"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhZQ3hXQWFVTGNRN7RTx4P"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}